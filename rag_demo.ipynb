{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f0f8d711",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pro/miniconda3/envs/agntrag/lib/python3.10/site-packages/crewai/telemetry/telemetry.py:7: UserWarning: pkg_resources is deprecated as an API. See https://setuptools.pypa.io/en/latest/pkg_resources.html. The pkg_resources package is slated for removal as early as 2025-11-30. Refrain from using this package or pin to Setuptools<81.\n",
      "  import pkg_resources\n",
      "/home/pro/miniconda3/envs/agntrag/lib/python3.10/site-packages/pydantic/_internal/_generate_schema.py:937: UserWarning: Mixing V1 models and V2 models (or constructs, like `TypeAdapter`) is not supported. Please upgrade `CrewAgentExecutor` to V2.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "from crewai_tools import PDFSearchTool\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from crewai_tools import tool\n",
    "from crewai import Crew\n",
    "from crewai import Task\n",
    "from crewai import Agent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23608498",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(\n",
    "openai_api_base=\"https://api.groq.com/openai/v1\",\n",
    "openai_api_key=os.environ [GROQ APT KEY],\n",
    "model_name \"1lama3-86-8192\",\n",
    "temperature-0.1,\n",
    "max tokens 1000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12275206",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "pdf_url = \"https://proceedings.neurips.cc/paper_files/paper/2017/file/3f5ee243547dee91fbd053c1c4a845aa-Paper.pdf\"\n",
    "response requests.get(pdf_url)\n",
    "with open(\"attenstion_is_all_you_need.pdf\", \"wb\") as file:\n",
    "file.write(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90e69ced",
   "metadata": {},
   "outputs": [],
   "source": [
    "# file: rag_demo.py\n",
    "from crewai_tools import PDFSearchTool\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 1. Build the tool\n",
    "# -------------------------------------------------\n",
    "rag_tool = PDFSearchTool(\n",
    "    # pdf=\"attention_is_all_you_need.pdf\",   # <-- make sure the file exists in cwd\n",
    "    config=dict(\n",
    "        # ---------- LLM (Groq) ----------\n",
    "        llm=dict(\n",
    "            provider=\"groq\",               # exact string required by crewai-tools\n",
    "            # api_key=None,                  # reads from env var GROQ_API_KEY\n",
    "            config=dict(\n",
    "                model=\"llama3-8b-8192\",    # any Groq model name\n",
    "                # temperature=0.5,        # uncomment if you want\n",
    "                # top_p=1,\n",
    "                # stream=True,\n",
    "            ),\n",
    "        ),\n",
    "        # ---------- Embedder (HuggingFace) ----------\n",
    "        embedder=dict(\n",
    "            provider=\"huggingface\",        # exact string\n",
    "            config=dict(\n",
    "                model=\"BAAI/bge-small-en-v1.5\",\n",
    "                # task_type=\"retrieval_document\",   # optional, default is fine\n",
    "                # title=\"Embeddings\",\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# -------------------------------------------------\n",
    "# 2. Quick test – ask a question about the PDF\n",
    "# -------------------------------------------------\n",
    "# question = \"What is the main contribution of the Transformer model?\"\n",
    "# answer = rag_tool.run(question)\n",
    "\n",
    "# print(\"\\n--- ANSWER ---\")\n",
    "# print(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221289f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_tool.run(\"What is the main contribution of the Transformer model?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfc40021",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"TAVILY_API_KEY\"] = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f545c82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool = TavilySearchResults(k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19be7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "web_search_tool.run(\"what is self attention mechansim in large languges model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9163611a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------------\n",
    "# 3. Web-search tool (DuckDuckGo – no API key needed)\n",
    "# --------------------------------------------------------------\n",
    "# web_search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "@tool\n",
    "def router_tool(question):\n",
    "\"\"\"Router Function\"\"\"\n",
    "if 'self attention' in question:\n",
    "    return 'vectorstore'\n",
    "else:\n",
    "    return 'web search'\n",
    "\n",
    "# @tool\n",
    "# def router_tool(question: str) -> str:\n",
    "#     \"\"\"Router that decides between vectorstore (PDF) and web search.\"\"\"\n",
    "#     # Simple keyword logic – you can replace with an LLM call later\n",
    "#     if \"self attention\" in question.lower() or \"transformer\" in question.lower():\n",
    "#         return \"vectorstore\"\n",
    "#     else:\n",
    "#         return \"web_search\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3a8f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Router_Agent = Agent(\n",
    "    role='Router',\n",
    "    goal='Route user question to a vectorstore or web search',\n",
    "    backstory=(\n",
    "        \"You are an expert at routing a user question to a vectorstore or web search. \"\n",
    "        \"Use the vectorstore for questions related to Retrieval-Augmented Generation (RAG), \"\n",
    "        \"vector databases, embeddings, or the 'Attention Is All You Need' paper. \"\n",
    "        \"You do not need to be stringent with the keywords in the question related to these topics.\"\n",
    "    ),\n",
    "    verbose True,\n",
    "    allow_delegation=False,\n",
    "    llm=llm,\n",
    ")\n",
    "\n",
    "# Router_Agent = Agent(\n",
    "#     role='Router',\n",
    "#     goal='Route user question to a vectorstore or web search',\n",
    "#     backstory=(\n",
    "#         \"You are an expert at routing a user question to a vectorstore or web search. \"\n",
    "#         \"Use the vectorstore for questions related to Retrieval-Augmented Generation (RAG), \"\n",
    "#         \"vector databases, embeddings, or the 'Attention Is All You Need' paper. \"\n",
    "#         \"You do not need to be stringent with the keywords in the question related to these topics.\"\n",
    "#     ),\n",
    "#     verbose=True,\n",
    "#     allow_delegation=False,\n",
    "#     llm=\"groq/llama3-8b-8192\",  # Fixed: was \"11m-11m\" → correct Groq model\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317944d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Retriever_Agent=Agent(\n",
    "role=\"Retriever\",\n",
    "goal=\"Use the information retrieved from the vectorstore to answer the question\",\n",
    "backstory=(\n",
    "\n",
    "\"You are an assistant for question-answering tasks.\"\n",
    "\"Use the information present in the retrieved context to answer the question.\"\n",
    "\"You have to provide a clear concise answer.\"\n",
    "),\n",
    "verbose=True,\n",
    "allow_delegation=False,\n",
    "llm=llm,\n",
    ")\n",
    "\n",
    "'''Use ChatGroq instance (recommended for control)'''\n",
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0.3)\n",
    "# Retriever_Agent = Agent(\n",
    "#     role=\"Retriever\",\n",
    "#     goal=\"Use the information retrieved from the vectorstore to answer the question\",\n",
    "#     backstory=(\n",
    "#         \"You are an assistant for question-answering tasks. \"\n",
    "#         \"Use the information present in the retrieved context to answer the question. \"\n",
    "#         \"You have to provide a clear and concise answer.\"\n",
    "#     ),\n",
    "#     verbose=True,\n",
    "#     allow_delegation=False,\n",
    "#     llm=llm,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33d89fa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Grader_agent=Agent(\n",
    "role=\"Answer Grader\",\n",
    "goal='Filter out erroneous retrievals',\n",
    "backstory=(\n",
    "\"You are a grader assessing relevance of a retrieved document to a user question.\"\n",
    "\"If the document contains keywords related to the user question, grade it as relevant.\"\n",
    "\"It does not need to be a stringent test. You have to make sure that the answer is relevant to the question.\"\n",
    ")\n",
    "verbose=True,\n",
    "allow=delegation=False,\n",
    "llm=llm,\n",
    ")\n",
    "\n",
    "'''Use ChatGroq for more control'''\n",
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0.1)\n",
    "# Grader_agent = Agent(\n",
    "#     role=\"Answer Grader\",\n",
    "#     goal=\"Filter out erroneous retrievals\",\n",
    "#     backstory=(\n",
    "#         \"You are a grader assessing the relevance of a retrieved document to a user question. \"\n",
    "#         \"If the document contains keywords related to the user question, grade it as relevant. \"\n",
    "#         \"It does not need to be a stringent test. You must ensure that the answer is relevant to the question.\"\n",
    "#     ),\n",
    "#     verbose=True,\n",
    "#     allow_delegation=False,\n",
    "#     llm=llm,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297d0d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "hallucination_grader=Agent(\n",
    "role=\"Hallucination Grader\",\n",
    "goal-\"Filter out hallucination\",\n",
    "backstory-(\n",
    "\"You are a hallucination grader assessing whether an answer is grounded in /supported by a set of facts.\"\n",
    "\"Make sure you meticulously review the answer and check if the response provided is in alignmnet with the question asked\"\n",
    "),\n",
    "verbose=True,\n",
    "allow_delegation=False,\n",
    "ll=llm,\n",
    ")\n",
    "'''Enhanced version with ChatGroq (recommended for precision)'''\n",
    "# from langchain_groq import ChatGroq\n",
    "# llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0.0)  # Low temp for factual grading\n",
    "# hallucination_grader = Agent(\n",
    "#     role=\"Hallucination Grader\",\n",
    "#     goal=\"Filter out hallucinations\",\n",
    "#     backstory=(\n",
    "#         \"You are a hallucination grader assessing whether an answer is grounded in and supported by a set of facts. \"\n",
    "#         \"Make sure you meticulously review the answer and check if the response provided is in alignment with the question asked. \"\n",
    "#         \"Output 'YES' if the answer is fully grounded, 'NO' if it contains hallucinations.\"\n",
    "#     ),\n",
    "#     verbose=True,\n",
    "#     allow_delegation=False,\n",
    "#     llm=llm,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e17a810",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer_grader=Agent(\n",
    "role=\"Answer Grader\",\n",
    "goal=\"Filter out hallucination from the answer.\",\n",
    "backstory=(\n",
    "\"You are a grader assessing whether an answer is useful to resolve a question.\"\n",
    "\"Make sure you meticulously review the answer and check if it makes sense for the question asked\"\n",
    "\"If the answer is relevant generate a clear and concise response.\"\n",
    "\"If the answer gnerated is not relevant then perform a websearch using 'web_search_tool\"\n",
    ")\n",
    "verbose=True,\n",
    "allow_delegation=False,\n",
    "llm=llm,\n",
    ")\n",
    "\n",
    "'''Enhanced Version with ChatGroq + Web Search Delegation'''\n",
    "# from langchain_groq import ChatGroq\n",
    "# from crewai_tools import tool\n",
    "# from langchain_community.tools import DuckDuckGoSearchRun\n",
    "\n",
    "# web_search_tool = DuckDuckGoSearchRun()\n",
    "\n",
    "# llm = ChatGroq(model=\"llama3-8b-8192\", temperature=0.1)\n",
    "\n",
    "# answer_grader = Agent(\n",
    "#     role=\"Answer Grader\",\n",
    "#     goal=\"Ensure the answer is relevant and grounded; fallback to web search if needed.\",\n",
    "#     backstory=(\n",
    "#         \"You are a grader assessing whether an answer is useful to resolve a question. \"\n",
    "#         \"Make sure you meticulously review the answer and check if it makes sense for the question asked. \"\n",
    "#         \"If the answer is relevant, generate a clear and concise response. \"\n",
    "#         \"If the answer is not relevant or contains hallucinations, use the 'web_search_tool' to find a better answer.\"\n",
    "#     ),\n",
    "#     verbose=True,\n",
    "#     allow_delegation=False,  # Keep False if you pass tools explicitly\n",
    "#     llm=llm,\n",
    "#     tools=[web_search_tool],  # Give it access to search\n",
    "# )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec82d07a",
   "metadata": {},
   "outputs": [],
   "source": [
    "router_task=Task(\n",
    "description=(\n",
    "    \"Analyze the keywords in the question: {question}\\n\"\n",
    "    \"Based on the keywords, decide whether it is eligible for a vectorstore search or a web search.\\n\"\n",
    "    \"Return a single word: 'vectorstore' if eligible for vectorstore search.\\n\"\n",
    "    \"Return a single word: 'websearch' if eligible for web search.\\n\"\n",
    "    \"Do not provide any preamble or explanation.\"\n",
    "),\n",
    "expected_output=(\n",
    "        \"A single word: either 'vectorstore' or 'websearch' based on the question.\\n\"\n",
    "        \"Do not provide any preamble or explanation.\"\n",
    "    ),\n",
    "agent=Router_Agent,\n",
    "tools=[router_tool],\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agntrag",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
